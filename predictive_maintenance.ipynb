{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "path ='C:/Users/Asger/data/predictive_maintenance/'\n",
    "\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(path + 'feature.csv', header=[0,1], index_col=0, sep=';')\n",
    "labels = pd.read_csv(path + 'train_label.csv')\n",
    "df = features.join(labels['label'])\n",
    "df.rename(columns={('Unnamed: 1_level_0','date'):'date'}, inplace=True)\n",
    "\n",
    "# Using only data with a label\n",
    "df.dropna(subset=['label'], inplace=True)\n",
    "\n",
    "df['date'] = pd.to_datetime(df.date, infer_datetime_format=True)\n",
    "date1 = df.date.sort_values().tolist()[0]\n",
    "date2 = df.date.sort_values().tolist()[-1]\n",
    "\n",
    "print('Start date: {}'.format(date1))\n",
    "print('End Date: {}'.format(date2))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = [col for col in df.columns if col[0] == 'count']  # Columns of count\n",
    "mean_cols = [col for col in df.columns if col[0] == 'mean']  # Columns of mean\n",
    "max_cols = [col for col in df.columns if col[0] == 'max']  # Columns of the last occurence timestamp\n",
    "min_cols = [col for col in df.columns if col[0] == 'min']  # Columns of the first occurence timestamp\n",
    "std_cols = [col for col in df.columns if col[0] == 'std']  # Columns of standard deviation\n",
    "\n",
    "cols = count_cols + mean_cols + max_cols + min_cols + std_cols\n",
    "\n",
    "# Removing collums with no informaiton or very little information\n",
    "emt_columns = [col for col in cols if df[col].sum()<2] \n",
    "df.drop(emt_columns, axis=1, inplace=True)\n",
    "\n",
    "# Adding new date fratures\n",
    "df['day_of_week'] = df['date'].apply(lambda x: x.dayofweek + 1)\n",
    "df['month'] = df['date'].apply(lambda x: x.month)\n",
    "df['week_of_month'] = df['date'].apply(lambda x: x.day//7+1)\n",
    "\n",
    "date_features = ['day_of_week', 'month', 'week_of_month']\n",
    "for d in date_features:\n",
    "    df = df.join(pd.get_dummies(df[d], prefix=d)).drop(d, axis=1)\n",
    "\n",
    "# Adding z-scores of min and max\n",
    "error_ids = [col[1] for col in df.columns if col[0] == 'count']\n",
    "error_ids.remove('136222250') #min and max is removed for this error, hence no z-score can be calculated\n",
    "\n",
    "for e in error_ids:    \n",
    "    df[('z_score_min', e)]=(df[('min', e)]-df[('mean', e)])/df[('std', e)]\n",
    "    df[('z_score_max', e)]=(df[('max', e)]-df[('mean', e)])/df[('std', e)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "count_cols = [col for col in df.columns if col[0] == 'count']  # Columns of count\n",
    "mean_cols = [col for col in df.columns if col[0] == 'mean']  # Columns of mean\n",
    "max_cols = [col for col in df.columns if col[0] == 'max']  # Columns of the last occurence timestamp\n",
    "min_cols = [col for col in df.columns if col[0] == 'min']  # Columns of the first occurence timestamp\n",
    "std_cols = [col for col in df.columns if col[0] == 'std']  # Columns of standard deviation\n",
    "z_score_min_cols = [col for col in df.columns if col[0] == 'z_score_min']  # Columns of standard deviation\n",
    "z_score_max_cols = [col for col in df.columns if col[0] == 'z_score_max']  # Columns of standard deviation\n",
    "\n",
    "cols = count_cols + mean_cols + max_cols + min_cols + std_cols+z_score_min_cols+z_score_max_cols \n",
    "# Fill NaN values with -1\n",
    "df.update(df[cols].fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>(count, 136088194)</th>\n",
       "      <th>(count, 136088202)</th>\n",
       "      <th>(count, 136088802)</th>\n",
       "      <th>(count, 136089546)</th>\n",
       "      <th>(count, 136110468)</th>\n",
       "      <th>(count, 136216674)</th>\n",
       "      <th>(count, 136222202)</th>\n",
       "      <th>(count, 136222210)</th>\n",
       "      <th>(count, 136222234)</th>\n",
       "      <th>...</th>\n",
       "      <th>(z_score_min, 136676666)</th>\n",
       "      <th>(z_score_max, 136676666)</th>\n",
       "      <th>(z_score_min, 136676682)</th>\n",
       "      <th>(z_score_max, 136676682)</th>\n",
       "      <th>(z_score_min, 136676698)</th>\n",
       "      <th>(z_score_max, 136676698)</th>\n",
       "      <th>(z_score_min, 136676714)</th>\n",
       "      <th>(z_score_max, 136676714)</th>\n",
       "      <th>(z_score_min, 136676754)</th>\n",
       "      <th>(z_score_max, 136676754)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2261</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2950</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2810</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  (count, 136088194)  (count, 136088202)  (count, 136088802)  \\\n",
       "1 2015-04-05                   0                   0                   0   \n",
       "2 2015-05-05                   0                   0                   0   \n",
       "3 2015-06-05                   0                   0                   0   \n",
       "4 2015-07-05                   0                   0                   0   \n",
       "5 2015-08-05                   0                   0                   0   \n",
       "\n",
       "   (count, 136089546)  (count, 136110468)  (count, 136216674)  \\\n",
       "1                   0                2250                   0   \n",
       "2                   0                1700                   0   \n",
       "3                   0                2261                   0   \n",
       "4                   0                2950                   0   \n",
       "5                   0                2810                   0   \n",
       "\n",
       "   (count, 136222202)  (count, 136222210)  (count, 136222234)  \\\n",
       "1                   1                   2                   0   \n",
       "2                   2                   5                   0   \n",
       "3                  10                   7                   0   \n",
       "4                   5                   8                   0   \n",
       "5                   7                   1                   0   \n",
       "\n",
       "             ...             (z_score_min, 136676666)  \\\n",
       "1            ...                                 -1.0   \n",
       "2            ...                                 -1.0   \n",
       "3            ...                                 -1.0   \n",
       "4            ...                                 -1.0   \n",
       "5            ...                                 -1.0   \n",
       "\n",
       "   (z_score_max, 136676666)  (z_score_min, 136676682)  \\\n",
       "1                      -1.0                      -1.0   \n",
       "2                      -1.0                      -1.0   \n",
       "3                      -1.0                      -1.0   \n",
       "4                      -1.0                      -1.0   \n",
       "5                      -1.0                      -1.0   \n",
       "\n",
       "   (z_score_max, 136676682)  (z_score_min, 136676698)  \\\n",
       "1                      -1.0                      -1.0   \n",
       "2                      -1.0                      -1.0   \n",
       "3                      -1.0                      -1.0   \n",
       "4                      -1.0                      -1.0   \n",
       "5                      -1.0                      -1.0   \n",
       "\n",
       "   (z_score_max, 136676698)  (z_score_min, 136676714)  \\\n",
       "1                      -1.0                      -1.0   \n",
       "2                      -1.0                      -1.0   \n",
       "3                      -1.0                      -1.0   \n",
       "4                      -1.0                      -1.0   \n",
       "5                      -1.0                      -1.0   \n",
       "\n",
       "   (z_score_max, 136676714)  (z_score_min, 136676754)  \\\n",
       "1                      -1.0                      -1.0   \n",
       "2                      -1.0                      -1.0   \n",
       "3                      -1.0                      -1.0   \n",
       "4                      -1.0                      -1.0   \n",
       "5                      -1.0                      -1.0   \n",
       "\n",
       "   (z_score_max, 136676754)  \n",
       "1                      -1.0  \n",
       "2                      -1.0  \n",
       "3                      -1.0  \n",
       "4                      -1.0  \n",
       "5                      -1.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07028753993610223"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].sum()/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create one-day in advance label\n",
    "df['label_1'] = df['label'].shift(-1)\n",
    "\n",
    "# Using only data with a label\n",
    "df.dropna(subset=['label_1'], inplace=True) #shift(-1) causes last observation to be without a label\n",
    "\n",
    "#Splitting data\n",
    "test_date= df.date.tolist()[-130]\n",
    "df_train = df[df.date<val_date]\n",
    "df_test = df[df.date>=val_date]\n",
    "\n",
    "#Define inputs\n",
    "train_x = df_train.drop(['label','label_1','date'],axis=1)\n",
    "train_y = df_train['label_1']\n",
    "\n",
    "test_x = df_test.drop(['label','label_1','date'],axis=1)\n",
    "test_y = df_test['label_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AutoML to create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.5426150121065374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.5430992736077481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.5806295399515738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.5806295399515738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.5806295399515738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 6 - Current best internal CV score: 0.6174334140435834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 7 - Current best internal CV score: 0.6217917675544793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 8 - Current best internal CV score: 0.6569007263922518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 9 - Current best internal CV score: 0.6569007263922518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10 - Current best internal CV score: 0.6569007263922518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: LogisticRegression(RFE(ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.3, min_samples_leaf=17, min_samples_split=11, n_estimators=100), criterion=entropy, max_features=0.35000000000000003, n_estimators=100, step=0.6500000000000001), C=10.0, dual=True, penalty=l2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.naive_bayes.GaussianNB': {}, 'sklearn.naive_bayes.BernoulliNB': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'fit_prior': [True, False]}, 'sklearn.naive_bayes.MultinomialNB': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'fit_prior': [True, False]}, 'sklearn.tree.DecisionT....3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])}}}},\n",
       "        crossover_rate=0.1, cv=5, disable_update_check=False,\n",
       "        early_stop=None, generations=10, max_eval_time_mins=2,\n",
       "        max_time_mins=None, memory=None, mutation_rate=0.9, n_jobs=1,\n",
       "        offspring_size=40, periodic_checkpoint_folder=None,\n",
       "        population_size=40, random_state=None, scoring=None, subsample=1.0,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_clf = TPOTClassifier(verbosity=2, generations=10, max_eval_time_mins=2, population_size=40, cv=5,scoring='roc_auc')\n",
    "tp_clf.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_clf.export('C:/Users/Asger/Dropbox/projects/tpot_exports/tpot_export_110119.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41087962962962965"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_pred = tp_clf.predict_proba(test_x)[:,:1]\n",
    "roc_auc_score(test_y, tpot_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5462962962962963"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "\n",
    "# Score on the training set was:0.6569007263922518\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.3, min_samples_leaf=17, min_samples_split=11, n_estimators=100)),\n",
    "    RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.35000000000000003, n_estimators=100), step=0.6500000000000001),\n",
    "    LogisticRegression(C=10.0, dual=True, penalty=\"l2\")\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(train_x, train_y)\n",
    "results = exported_pipeline.predict(test_x)\n",
    "\n",
    "tpot_pred = exported_pipeline.predict_proba(test_x)[:,:1]\n",
    "roc_auc_score(test_y, tpot_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
